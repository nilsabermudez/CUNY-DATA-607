---
title: "Project 3"
author: "Gabrielle Bartomeo, Binish Chandy, Zach Dravis, Burcu Kaniskan, Niteen Kumar, Betsy Rosalen"
date: "March 25, 2018"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    number_section:  true
    theme: cerulean
    highlight:  tango
editor_options: 
  chunk_output_type: inline
---

```{r global_options, echo=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
```

```{r setup, include=FALSE}
library(knitr)
library(tidyverse)
library(DT)
library(kableExtra)
library(lubridate)
library(janitor)
library(likert)
library(reshape)
library(plotly)
library(scales)
library(grid)
library(gridExtra)
knitr::opts_chunk$set(echo = FALSE)
```

<br>

# Research Question

The goal of this project is to answer the research question **Which are the most valued data science skills?**  

In order to answer that question we found and used survey data from the [Kaggle ML and Data Science Survey, 2017](https://www.kaggle.com/kaggle/kaggle-survey-2017).

While the answer to the question is by definition subjective, the Kaggle Survey was, "an industry-wide survey to establish a comprehensive view of the state of data science and machine learning" and with over 16,000 responses it provides a good starting point for exploring the views of professionals in the field and what they value.

<br>

# Importing data

The survey was stored in 2 different files consisting of:

  1. multiple choice items
  2. free-response items
  
We chose to focus on the multiple choice data only for statistical analysis.  Kaggle stored each data in csv format. We downloaded the multiple choice item survey results in csv format and placed it in our [GitHub repo](https://github.com/betsyrosalen/DATA_607_Project_3).

```{r message=FALSE, warning=FALSE}
linkMC<-"https://raw.githubusercontent.com/betsyrosalen/DATA_607_Project_3/master/project3_master/rawdata/multipleChoiceResponses.csv"
#importing MC items
MC<-read_csv (linkMC)

survey.data <- MC
#lets create a unique ID variable 
MC$id <- seq.int(nrow(MC))
```

```{r message=FALSE, warning=FALSE}
# Ignore this code Importing conversion rates data incase we want to do analyses 

# link_conversion<-"https://raw.githubusercontent.com/betsyrosalen/DATA_607_Project_3/master/project3_master/rawdata/conversionRates.csv"
# #importing MC items
# conversion<-read_csv (link_conversion)
# dim(conversion)
# #lets create a unique ID variable 
# conversion$id <- seq.int(nrow(conversion))
```

<br>

# A Day in a Data Scientist's Life

We start with exploring the resources utilized by Kaggle survey users for learning data science. What are the different data science activities they do, what are the different learning platforms they use and how do they feel about the userfulness of those platforms?

>Insights into the demographics : How respondents data is distributed across different countries and also some interesting facts about country-wise gender distribution

## Variables and their definition 

To begin with, we focussed on users/ respondents demographics to understand the age group and their gender. 

After analyzing data, variables:GenderSelect & Age, it appears that out of 16716 global Kaggle respondents there are 13610 males and 2778 females. In this subset male respondents are almost 5 (~4.8) times more than female respondents. Also, from the plot below it is pretty evident that repondents' age peaks at 25 for both males and females whereas the median age is about 30.

```{r niteen01, echo=FALSE,warning=FALSE, cache=FALSE, message=FALSE}

survey.demographics <- survey.data%>%
  select(GenderSelect,Country,Age,EmploymentStatus) %>%
  filter(Country!='NA',trimws(Country)!='',Age!='NA',trimws(GenderSelect) %in% c('Male','Female'))

survey.dem.age.plot <- survey.demographics %>%
    group_by(Age,GenderSelect) %>%
    summarise(count=n()) %>%
    arrange(desc(count))

survey.dem.plot <- survey.demographics %>%
  group_by(Age,Country,GenderSelect,EmploymentStatus) %>%
  summarise(count=n()) %>%
  arrange(desc(count))

```

```{r figds01,  echo=FALSE,warning=FALSE,}
library(ggplot2)
ggplot(data = survey.dem.age.plot, 
       mapping = aes(x = Age, fill = GenderSelect, 
                     y = ifelse(test = GenderSelect == "Male", 
                                yes = -count, no = count)))+
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = abs, limits = max(survey.dem.age.plot$count) * c(-1,1)) +
  labs(y = "Count") +
  coord_flip()+
  theme_bw()

``` 

<br>

Since, we are trying to determine what the most important **Data Science Skills** are, it is very important to understand what a data scientist does. What are the different activities a data scientist performs on daily basis, and how much time does each activity typically take?

<br>

> Let’s take a peek at a day in the life of a Data Scientist and try to figure out what a data scientist does.

![ ](./dsact.jpg)


The day typically starts with a question or business problem and invloves following activties/ tasks:

1. **GatheringData** 
2. **FindingInsights** 
3. **ModelBuilding**
4. **Visualizing**
5. **Production** 

## Manipulating data

Kaggle successfully captured repondents' data about time spent in different activities. In order to analyze this question we looked at attributes: TimeGatheringData, TimeModelBuilding, TimeProduction, TimeVisualizing, and TimeFindingInsights.

In order to determining usefulness of learners platfom we tidy the data for 18 learning platform attributes present in the data set and perform the analysis on long data type. We also successffuly manipulated data to find user's sentiments/ remarks from platform usefulness standpoint. 

## Exploratory Data Analysis (EDA)

After analyzing data for US repondents it appears that data aquisition or gathering data is the main activitiy, at 37.75%.  This is where a data scientist spends most of their time. Model building ranks 2nd, at 19.23%, followed by time spent in finding insights and data visualization. Only 10.23% of their total time appears to be taken by production activities. 

```{r niteen02, echo=FALSE,warning=FALSE, cache=FALSE, message=FALSE}

survey.data.ds.activities <- survey.data %>%
    select(GenderSelect,Country,Age,EmploymentStatus,PublicDatasetsSelect,FormalEducation,MajorSelect,
           DataScienceIdentitySelect,CurrentJobTitleSelect,
          TimeGatheringData,TimeModelBuilding,TimeProduction,TimeVisualizing,TimeFindingInsights) %>%
          filter(Age!='NA',Country!='NA',Country!='',GenderSelect %in% c('Male', 'Female'),
          TimeGatheringData!='NA',TimeModelBuilding!='NA',TimeProduction!='NA',TimeVisualizing!='NA',
          TimeFindingInsights!='NA',MajorSelect!='',PublicDatasetsSelect!='NA',
          FormalEducation %in% c('Master\'s degree', 'Doctoral degree', 'Bachelor\'s degree')
          )

survey.data.ds.activities$dsid <- seq.int(nrow(survey.data.ds.activities))

ds.act.tidy <- survey.data.ds.activities %>%
          gather( DSActivity,act_count,TimeGatheringData:TimeFindingInsights) %>%
          arrange(dsid)
ds.act.df <- ds.act.tidy %>%
    select(dsid,Country,EmploymentStatus,DSActivity,act_count) %>%
    group_by(DSActivity)

#kable(head(ds.act.df))

ds.act.us <- filter(ds.act.df,Country=='United States')
ds.act.us.plot <- ds.act.us %>%
    group_by(DSActivity) %>%
    summarise(mean_precent=mean(act_count))

ds.act.us.plot.df <-  ds.act.us.plot %>%   
  arrange(desc(mean_precent))
kable(ds.act.us.plot.df)
```


```{r fig01, fig.height = 5, fig.width = 7, fig.align = "center" , message= FALSE, echo=FALSE}
ggplot(data = ds.act.us.plot,aes(DSActivity,mean_precent))+
  geom_bar(stat = 'identity',aes(fill=DSActivity))+  
  geom_text(aes(x = DSActivity, y = mean_precent, label = paste(round(mean_precent,2),'%'),
                                    group = DSActivity,vjust = -0.2))+
  labs(title = "Comparing Data Science Activities (Country:US)",x = "Data Science Activities", y = "Time Spent in %") +
  theme_bw()+
  theme(axis.text.x = element_text(angle = 65, hjust = 1),legend.position = 'none')
```

Whether one is employed full-time, part-time or a student; its worth exploring how people are using different learning platforms and how they feel about them. We made use of different learning platform attributes captured in the dataset which also includes Kaggle as a learning platform.

```{r niteen04, echo=FALSE,warning=FALSE, cache=FALSE, message=FALSE}
survey.data.learning <- survey.data %>%
    select(GenderSelect,Country,Age,EmploymentStatus,StudentStatus,LearningDataScience,CareerSwitcher,PublicDatasetsSelect,
           FormalEducation,MajorSelect,DataScienceIdentitySelect,CurrentJobTitleSelect,WorkChallengesSelect,
           LearningPlatformSelect,LearningPlatformUsefulnessArxiv,LearningPlatformUsefulnessBlogs,LearningPlatformUsefulnessCollege,
           LearningPlatformUsefulnessCompany,LearningPlatformUsefulnessConferences,LearningPlatformUsefulnessFriends,
           LearningPlatformUsefulnessKaggle,LearningPlatformUsefulnessNewsletters,LearningPlatformUsefulnessCommunities,
           LearningPlatformUsefulnessDocumentation,LearningPlatformUsefulnessCourses,LearningPlatformUsefulnessProjects,
           LearningPlatformUsefulnessPodcasts,LearningPlatformUsefulnessSO,LearningPlatformUsefulnessTextbook,
           LearningPlatformUsefulnessTradeBook,LearningPlatformUsefulnessTutoring,LearningPlatformUsefulnessYouTube,
           BlogsPodcastsNewslettersSelect,LearningDataScienceTime) %>%
    filter(Age!='NA',Country!='NA',Country!='',GenderSelect %in% c('Male', 'Female'))
survey.data.learning$lid <- seq.int(nrow(survey.data.learning))

survey.data.learning.tidy <- gather(survey.data.learning, LPlatform,LP_count,
                                    LearningPlatformUsefulnessArxiv:LearningPlatformUsefulnessYouTube) %>%
                          arrange(lid)

survey.data.learn.df  <- survey.data.learning.tidy %>%
    select(lid,Country,EmploymentStatus,LPlatform,LP_count) %>%
    group_by(LPlatform)

learn.df <- survey.data.learn.df %>%
    filter(LP_count!='NA', LP_count!='')

#learn.df <- rename(learn.df,LearnerRemarks=LP_count)

ds.learn.us <- filter(learn.df,Country=='United States')
ds.learn.us.plot <- ds.learn.us %>%
    group_by(LPlatform) 
ds.learn.us.plot.df <- ds.learn.us.plot %>%
    mutate(LearningPlatform=substr(LPlatform,27,length(LPlatform))) 
kable(head(ds.learn.us.plot.df))
```


```{r fig02, fig.height = 7, fig.width = 8 , fig.align = "center" , message= FALSE, echo=FALSE}
ggplot(data = ds.learn.us.plot.df,aes(LearningPlatform,LP_count))+
  geom_bar(stat = 'identity',aes(fill=LP_count))+  
    labs(title = "Learning Platform Usage and Remarks (Country:US)", 
                         x = "Learning Platform Type", 
                         y = "Learners Sentiments") +
theme_bw()+
theme(axis.text.x = element_text(angle = 65, hjust = 1),axis.text.y=element_blank(),axis.ticks.y=element_blank())
```

After analyzing respondents take on different learning platforms it appears that learners mostly benefited from personal projects as majority of resonses indicate projects as being very useful. Online courses appears to be 2nd, followed by StackOverflow and Kaggle. Blogs,textbooks and college also appear to be very userful whereas newsletters, podcasts and tradebook rank low. 

<br>

# What do Data Scientists Want to Learn?

Next, we examine what these survey takers of various educational backgrounds find themselves excited to learn. Due to the ever-evolving nature of technology and, by extension, data science, it is imperative that they remain relevant in their field and are passionate in their pursuit for relevance.  Understanding what working professionals want to learn could give us insight into what skills are most valued in the field.

Does survey takers' formal education have any relationship to the Machine Learning/Data Science method he or she is most excited about learning in the next year?

## Variables and their definition 

To do the analysis, we concentrate on two columns in the dataset 

  1. FormalEducation: Which level of formal education have you attained?
  2. MLMethodNextYearSelect : Which Machine Learning/Data Science method are you most excited about learning in the next year?

These questions were asked to all participants.

```{r, echo=FALSE}
# removing NAs as they are not meaningful
subset <- MC %>%
        filter(!is.na(FormalEducation), !is.na(MLMethodNextYearSelect)) %>%
        select(FormalEducation, MLMethodNextYearSelect) %>%
        filter(FormalEducation != "I prefer not to answer") %>%
        mutate (FormalEducation=as.factor(FormalEducation)) %>%
        mutate (FormalEducation=recode_factor(FormalEducation,
                "Bachelor's degree"='Bachelor',
      "Some college/university study without earning a bachelor's degree"=
                                                      'College Dropout',
                                              'Doctoral degree'='Doctoral',
                                              "Master's degree"='Masters',
                                              'Professional degree'=
                                                      'Professional' ,
                'I did not complete any formal education past high school'=
                                                      'High School'))

```

## Exploratory Data Analysis (EDA)

First we plot the distribution of formal education in the dataset

```{r, echo=FALSE}

subset %>%
        ggplot(aes(x = FormalEducation, y = ..prop.., group = 1, fill="red") )+
        geom_bar(show.legend = FALSE,color = "red") +
        coord_flip() +
        labs (y="Proportion", x="Formal Education" , title="Distribution of Formal Education")


```

The data set predominantly contains candidates with Master's degrees which are followed by Bachelor's then doctoral degrees.   

Now let's look at the different Machine Learning/Data Science methods in the dataset.

```{r, echo=FALSE}
kable(unique(subset$MLMethodNextYearSelect), col.names = c("Machine Learning/Data Science"))
```

Now we can plot the distribution of Machine Learning/Data Science methods with formal education.

```{r, fig.height = 17, fig.width = 17, fig.align = "center" , message= FALSE, echo=FALSE}
subset %>%
        ggplot() + 
        geom_bar(mapping = aes(x = MLMethodNextYearSelect, fill = MLMethodNextYearSelect)) +
                 coord_flip() + 
                 theme(legend.position="bottom")+
                 facet_wrap (~FormalEducation)+
                 theme(axis.text.x = element_text(angle = 90), legend.position = 'none') +
                 labs (x="ML Method ", y="count " , title="Formal Education vs Machine Learning/Data Science method excited about learning next year")
```
```{r, echo=FALSE}
result <- subset %>%
        group_by(FormalEducation, MLMethodNextYearSelect) %>%
        summarise(count = n()) %>%
        mutate(percentage = round(count / sum(count), 2)) %>%
         mutate(rank = min_rank(desc(percentage))) %>%  
        filter(rank %in% c(1,2,3)) %>%
        select(-count, -rank) %>%
        arrange(FormalEducation, desc(percentage)) 
datatable(result, colnames=c("Formal Education", "Machine Learning/Data Science method excited about learning next year", "Percent"),class = 'cell-border stripe',caption = 'Table 1: Descriptive Statistics',options = list(pageLength = 8, dom = 'tip'))
```


Our results revealed that *Deep Learning* is the top most Machine Learning/Data Science method among the Kaggle survey takers regardless of their earned formal education. Interestingly, both 40% of respondents who had earned bachelor degree and 40% of survey takers with earned master’s degree stated that Deep Learning is the technique that they are most excited about learning in the next year. Similarly, 39% of the respondents with high school degree reported to learn Deep Learning as their top desired Machine Learning/Data Science method.

Following Deep Learning, *Neural Nets* emerged as the second top Machine Learning/Data Science method that Data Scientists have the desire to learn next year. Intriguingly, College Dropouts have highest percentage in the distribution in learning Neural Nets.

*Time Series Analysis* was found to be the third Machine Learning/Data Science method of interest. High school graduates want to learn Genetic & Evolutionary Algorithms as their third choice. 

Among doctoral survey takers, *Bayesian Methods* is the third preference. This particular  Machine Learning/Data Science method was not choice for others but only with PhDs. 

The results are suggesting that there is a clear trend among the data scientists that Deep Learning is the Machine Learning/Data Science method they want to learn. As to the global research question of interest what data science skills are valued the most, the results from this insight suggest that aspiring data scientists should consider learning Deep Learning.

<br>

# Data Science Methods

What are the most frequently used data science (DS) methods by those writing code in DS professions? Do those relate to formal educational attainment?

The Kaggle dataset provides multiple different variables to assess what the most valuable data science skills may be.  In the previous section, we examined what data science methods learners are most excited about and working on.  In this section, we'll look at which data science methods are the most frequently used and if that has any relationship to educational attainment--a potential indicator of whether or not certain methods require advanced academic training.

## Variables and their definition 

The following variables label questions asking survey respondents how often they use each of these data science methods.  Response options were: Rarely, Sometimes, Often, Most of the time

  - WorkMethodsFrequencyA/B
  - WorkMethodsFrequencyAssociationRules
  - WorkMethodsFrequencyBayesian
  - WorkMethodsFrequencyCNNs
  - WorkMethodsFrequencyCollaborativeFiltering
  - WorkMethodsFrequencyCross-Validation
  - WorkMethodsFrequencyDataVisualization
  - WorkMethodsFrequencyDecisionTrees
  - WorkMethodsFrequencyEnsembleMethods
  - WorkMethodsFrequencyEvolutionaryApproaches
  - WorkMethodsFrequencyGANs
  - WorkMethodsFrequencyGBM
  - WorkMethodsFrequencyHMMs
  - WorkMethodsFrequencyKNN
  - WorkMethodsFrequencyLiftAnalysis
  - WorkMethodsFrequencyLogisticRegression
  - WorkMethodsFrequencyMLN
  - WorkMethodsFrequencyNaiveBayes
  - WorkMethodsFrequencyNLP
  - WorkMethodsFrequencyNeuralNetworks
  - WorkMethodsFrequencyPCA
  - WorkMethodsFrequencyPrescriptiveModeling
  - WorkMethodsFrequencyRandomForests
  - WorkMethodsFrequencyRecommenderSystems
  - WorkMethodsFrequencyRNNs
  - WorkMethodsFrequencySegmentation
  - WorkMethodsFrequencySimulation
  - WorkMethodsFrequencySVMs
  - WorkMethodsFrequencyTextAnalysis
  - WorkMethodsFrequencyTimeSeriesAnalysis

The additional variables used for this analysis will include:

  - Formal Education

## Manipulating data

In order to answer the question of which methods are most popular among code writers, several transformations must first be done.  First, we filter the dataset down to only those who were classified as code writers: those that were employed in some capacity working in data science and writing code as part of their job duties.  Additionally, we include only participants who endorsed at least one data science skill on the question, "At work, which data science methods do you use? (Select all that apply)" with variable name :WorkMethodsSelect.

Once filtered, the endorsed data science methods were aggregated and plotted for frequency (see Exploratory Data Analysis below).  The top five most frequent data science methods endorsed were then selected and given a frequency score to represent among those who endorse using them to some extent, how frequently they use that tool.

The final transformation performed on the data was grouping by formal education level attainment and then identifying the most frequently endorsed data science methods for each group.  This can help identify if those writing certain types of code and using certain data analyses are potentially benefitted by pursuing advanced education--a valuable insight for potential data science pupils.

```{r}
#Subset Data
MethodsData <- MC %>%
  select(FormalEducation, contains("WorkMethods"))

#Filter data based on who answered the methods questions, which were only given to coding workers employed in some capacity
MethodsData <- MethodsData[!is.na(MethodsData$WorkMethodsSelect),]

#Most popular techniques that respondents report using at least rarely
MasterString <- MethodsData$WorkMethodsSelect
Options <- str_c(MasterString, collapse = "")
Options <- unlist(str_split(MasterString, pattern = ","))
Options <- as.data.frame(table(Options))
MethodsFrequency <- arrange(Options, desc(Freq))

#Find out when one knows a technique, how frequently they use it
#Rarely, Sometimes, Often, Most of the time
MethodsScored <- MethodsData %>%
  select(-c(WorkMethodsSelect))
MethodsScored[MethodsScored=="Rarely"]<-1
MethodsScored[MethodsScored=="Sometimes"]<-2
MethodsScored[MethodsScored=="Often"]<-3
MethodsScored[MethodsScored=="Most of the time"]<-4

MethodsScored$WorkMethodsFrequencyDataVisualization <- as.integer(MethodsScored$WorkMethodsFrequencyDataVisualization)
AvgFreqDataVis <- sum(MethodsScored$WorkMethodsFrequencyDataVisualization, na.rm = T) / sum(!is.na(MethodsScored$WorkMethodsFrequencyDataVisualization))

MethodsScored$WorkMethodsFrequencyLogisticRegression <- as.integer(MethodsScored$WorkMethodsFrequencyLogisticRegression)
AvgFreqLogRegress <- sum(MethodsScored$WorkMethodsFrequencyLogisticRegression, na.rm = T) / sum(!is.na(MethodsScored$WorkMethodsFrequencyLogisticRegression))

MethodsScored$`WorkMethodsFrequencyCross-Validation` <- as.integer(MethodsScored$`WorkMethodsFrequencyCross-Validation`)
AvgFreqCrossValid <- sum(MethodsScored$`WorkMethodsFrequencyCross-Validation`, na.rm = T) / sum(!is.na(MethodsScored$`WorkMethodsFrequencyCross-Validation`))

MethodsScored$WorkMethodsFrequencyDecisionTrees <- as.integer(MethodsScored$WorkMethodsFrequencyDecisionTrees)
AvgFreqDecisionTrees <- sum(MethodsScored$WorkMethodsFrequencyDecisionTrees, na.rm = T) / sum(!is.na(MethodsScored$WorkMethodsFrequencyDecisionTrees))

MethodsScored$WorkMethodsFrequencyRandomForests <- as.integer(MethodsScored$WorkMethodsFrequencyRandomForests)
AvgFreqRandomForest <- sum(MethodsScored$WorkMethodsFrequencyRandomForests, na.rm = T) / sum(!is.na(MethodsScored$WorkMethodsFrequencyRandomForests))

Top5FreqScore <- data.frame(Method = c("Data Visualization", "Logistic Regression", "Cross Validation", "Decision Trees", "Random Forests"), FrequencyScore = c(AvgFreqDataVis, AvgFreqLogRegress, AvgFreqCrossValid, AvgFreqDecisionTrees, AvgFreqRandomForest))

#Group and create methods frequency for each level of educational attainment
EducationData <- MethodsData %>%
  select(FormalEducation, WorkMethodsSelect) %>%
  filter(FormalEducation != "I prefer not to answer") %>%
  na.omit()

HighSchoolEducation <- EducationData %>%
  filter(FormalEducation == "I did not complete any formal education past high school")

SomePostSecondaryEducation <- EducationData %>%
  filter(FormalEducation == "Some college/university study without earning a bachelor\'s degree")

ProfessionalEducation <- EducationData %>%
  filter(FormalEducation == "Professional degree")

BachelorsEducation <- EducationData %>%
  filter(FormalEducation == "Bachelor's degree")

MastersEducation <- EducationData %>%
  filter(FormalEducation == "Master's degree")

DoctoralEducation <- EducationData %>%
  filter(FormalEducation == "Doctoral degree")

MethodFrequencyFunction <- function(x){
  BigString <- x$WorkMethodsSelect
  Selections <- str_c(BigString, collapse = "")
  Selections <- unlist(str_split(BigString, pattern = ","))
  TempDF <- as.data.frame(table(Selections))
  TempDF <- TempDF %>%
    mutate(RelativeFreq = Freq / sum(Freq))
  return(TempDF)
}

HighSchoolEducation <- MethodFrequencyFunction(HighSchoolEducation)
SomePostSecondaryEducation <- MethodFrequencyFunction(SomePostSecondaryEducation)
ProfessionalEducation <- MethodFrequencyFunction(ProfessionalEducation)
BachelorsEducation <- MethodFrequencyFunction(BachelorsEducation)
MastersEducation <- MethodFrequencyFunction(MastersEducation)
DoctoralEducation <- MethodFrequencyFunction(DoctoralEducation)
```

## Exploratory Data Analysis (EDA)

Following manipulation of the Kaggle data set, we created plots to visualize the aforementioned research questions.  First, here is a look at the frequency with which the following data science methods were endorsed by a total of 7,773 respondents.  Nearly 2/3 of the survey respondents endorsed the first place skill, data visualization.  Over half endorse logistic regression and just shy of half endorse cross-validation and decision trees.

```{r}
kable(MethodsFrequency)
```

The following plot graphically displays the frequency of endorsements for the data science methods asked about.

```{r}
MethodsFrequencyPlot <- ggplot(MethodsFrequency, aes(x = reorder(Options, -Freq), y = Freq, fill = Options)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ggtitle("Frequency of Enodrsements for DS Methods") + 
  xlab("Number of Endorsements") +
  ylab("Data Science Method") +
  guides(fill = F)

MethodsFrequencyPlot
```

In this plot we show the "Frequency Score" for the Top Five most endorsed data science methods.  It's important to break this down further than endorsement, as the above table and plot only consider which data science methods one uses at all. Just because a method is endorsed, doesn't mean that individuals use it frequently.  It may be a rare but essential method in data science. To get a more fine grained understanding of how commonly one uses a given data science method on the job, the kaggle survey followed up each endorsed method by asking respondents if they use it Rarely, Sometimes, Often, Most of the time.  We converted these to numeric values (Rarely = 1; Sometimes = 2, Often = 3, and Most of the time = 4) in order to graph a score and average the categorical responses.

```{r}
Top5EndorsedFreqScorePlot <- ggplot(Top5FreqScore, aes(x = reorder(Method, -FrequencyScore), y = FrequencyScore, fill = Method)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ggtitle("Average Frequency Scores for Top 5 Endorsed DS Methods") + 
  xlab("Average Frequency Score") +
  ylab("Data Science Method")

Top5EndorsedFreqScorePlot
```

Of the top five data science methods endorsed, data visualization was the skill indicated to be used the most frequently.

The below plots show the frequency of methods endorsed for each formal education level assessed by Kaggle.

```{r, fig.height = 15, fig.width = 15, fig.align = "center"}
HighSchoolPlot <- ggplot(HighSchoolEducation, aes(x = Selections, y = RelativeFreq, fill = Selections)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ggtitle("High School Education Methods Usage") +
  guides(fill = F)

SomeSchoolPlot <- ggplot(SomePostSecondaryEducation, aes(x = Selections, y = RelativeFreq, fill = Selections)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ggtitle("Some Post Secondary Education Methods Usage") +
  guides(fill = F)

ProfessionalPlot <- ggplot(ProfessionalEducation, aes(x = Selections, y = RelativeFreq, fill = Selections)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ggtitle("Professional Education Methods Usage") +
  guides(fill = F)

BachelorsPlot <- ggplot(BachelorsEducation, aes(x = Selections, y = RelativeFreq, fill = Selections)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ggtitle("Bachelor's Education Methods Usage") +
  guides(fill = F)

MastersPlot <- ggplot(MastersEducation, aes(x = Selections, y = RelativeFreq, fill = Selections)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ggtitle("Master's Education Methods Usage") +
  guides(fill = F)

DoctoralPlot <- ggplot(DoctoralEducation, aes(x = Selections, y = RelativeFreq, fill = Selections)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ggtitle("Doctoral Education Methods Usage") +
  guides(fill = F)

grid.arrange(HighSchoolPlot, SomeSchoolPlot, ProfessionalPlot, BachelorsPlot, MastersPlot, DoctoralPlot, nrow = 2)
```

We see that in the majority of educational attainment brackets, data visualization remains the most frequently endorsed data science method.

The same information is also provided in tabular format:

```{r}
HighSchoolEducation$Degree <- "High School Education"
SomePostSecondaryEducation$Degree <- "Some Post Secondary Education"
ProfessionalEducation$Degree <- "Professional Education"
BachelorsEducation$Degree <- "Bachelor's Education"
MastersEducation$Degree <- "Master's Education"
DoctoralEducation$Degree <- "Doctoral Education"

AllEducations <- rbind(HighSchoolEducation, SomePostSecondaryEducation, ProfessionalEducation, BachelorsEducation, MastersEducation, DoctoralEducation)

Top3EachDegree <- AllEducations %>%
  group_by(Degree) %>%
  arrange(desc(RelativeFreq)) %>%
  slice(1:3)

kable(Top3EachDegree)
```

Answering the research question of which data science skills are the most important can be interpreted and answered in many ways.  One way to explore this deceivingly complex question is to analyze which data science methods are endorsed as being used by code writers on the job.  This analysis did just that, and further explored the Top 5 most endorsed data science methods by seeing how frequently those that endorsed them actually use those methods on the job.

The bottom line of this analysis is to consider data visualization, logistic regression, cross-validation, decision trees, and random forests as not only frequently endorsed methods, but as methods that are not only essential but used in small ways.  It seems like across data science code writers, these methods are popular and then for individual data science code writers, they are used frequently.

The second goal of this analysis was to understand how formal educational attainment relates to data science methods used on the job.  When looking at the plots of each educational level and the table coalescing all of that data, it does not seem like data science methods used by code writers differ given the educational level.  Data visualization remains the most frequently endorsed data science method for the majority of educational groups.  This has important implications for students of data science in understanding that certain popular job functions are not only performed by those with advanced degrees.  This speaks to how crucial skills like data visualization and the other frequently endorsed and commonly used methods are to data science as a whole.

<br>

# 'Learners' vs. Employed Data Scientists

```{r message=FALSE ,warning=FALSE, echo=FALSE}
#Re-import MC items using read.csv so that I can use the likert package
MC2<-read.csv(linkMC, stringsAsFactors = FALSE)
#lets create a unique ID variable 
MC2$id <- seq.int(nrow(MC2))
```

Is there a difference between what 'Learners' think are the important skills to learn and what employed Data Scientists say are the skills and tools they are using?

Those who are new to data science and learning new skills may have different opinions about which tools and methods are most important to learn and which are being used than those who are already employed in the field. Comparing the answer of 'Learners' vs. employed Data Scientists may give us some insight into which skills each group values most and whether or not they are in agreement.

## Variables and their definition

A large portion of the data collected in the Kaggle survey was in the form of Likert scales asking respondents to place the value, importance, or frequency of use of certain skills, tools and methods on a 3-4 point scale.  To answer our question about which are the 'most valued' data science skills we looked a these scales and analyzed for differences between what 'Learners' thought was important to them vs. what employed data scientists say they are using in the field.  

An oversight in the survey is that they failed to capture the opinions of those who are employed about what they thought were the most important job skills.  They didn't bother to ask employed respondents those questions, so comparisons between employed data scientists and learners are a little more difficult.  We can only use the data about what tools and methods employed data scientists are actually using and the frequency of their use to infer the importance of those tools and methods.  The Survey also failed to capture those who are employed and ALSO students or learners!  They didn't bother to ask employed respondents if they were also studying Data Science.  Professional development is critical in a field that is growing and changing as rapidly as data science, so asking employed professionals about their further studies could have been very useful information to have.  Working Data Scientists may have a better insight into what direction the field is going in than students who are just in the learning phase of their journey.

## Manipulating data

Out of the 229 variables of data collected in the survey, about 105 of them fall into 5 likert scales describing, the "Learning Platform Usefulness" (which was asked of both learners and employed data scientists), "Job Skill Importance" (which only unemployed learners were asked), "Work Tools Frequency" and "WorkMethodsFrequency" (which only employed data scientists were asked to answer).  We narrowed down the data to include only these as well as a few more basic demographic fields to get a sense of who the respondents are.

We also chose to focus only on respondents who are located in the US since international cultural and technological differences may skew results.  Different tools and skills may be more or less valued in different countries, so we thought it best to narrow the focus on one country at a time.  Further analysis to see if the findings are consistent across countries would be interesting and worthwhile.

```{r, echo=FALSE}
# Select only variables that seem most related to “Which are the most valued data science skills?”
# Filter for US Only
USOnly <- MC2 %>%
  select(-c(56:73, 76:79, 167:196, 198:228)) %>%
  filter(Country=='United States')

cols <- str_replace(names(USOnly), "LearningPlatformUsefulness", "LPU-")
cols <- str_replace(cols, "JobSkillImportance", "JSI-")
cols <- str_replace(cols, "WorkToolsFrequency", "WTF-")
cols <- str_replace(cols, "WorkMethodsFrequency", "WMF-")
names(USOnly) <- cols
remove(MC2)
```

```{r warning=FALSE, include=FALSE}
# Separate those employed in Data Science from those who are not.

# Filter for Employed only, TitleFit better than 'Poorly', and CodeWriters only
# Remove those that said they are "Employed by a company that doesn't perform advanced analytics"
employed <- USOnly %>%
  filter(!grepl('Not employed',EmploymentStatus), 
         TitleFit!="Poorly",
         !grepl('doesn\'t perform advanced analytics',CurrentEmployerType),
         CodeWriter=="Yes",
         JobFunctionSelect != 'Build and/or run the data infrastructure')
  
# Filter for Data Science Learners who are not employed.  
# The Survey failed to capture those who are employed and ALSO students or learners!!!  
# Didn't bother to ask employed respondents if they were also sudying Data Science.
learner <- USOnly %>%
  filter(grepl('Not employed',EmploymentStatus),
         grepl('Yes',LearningDataScience))

# Change empty strings to NA
is.na(employed) <- employed == ""
is.na(learner) <- learner == ""

# Get rid of empty columns 
employed <- remove_empty(employed, c("cols"))
learner <- remove_empty(learner, c("cols"))
glimpse(employed)
glimpse(learner)
```

```{r, include=FALSE}
# Change columns to factors

flevels <- function(x){
  factor(x, order=TRUE, levels=c("Not Useful", "Somewhat useful", "Very useful"))
}
flevels2 <- function(x){
  factor(x, order=TRUE, levels=c("Rarely", "Sometimes", "Often", "Most of the time"))
}
flevels3 <- function(x){
  factor(x, order=TRUE, levels=c("Unnecessary", "Nice to have", "Necessary"))
}

employed[,14:31] <- lapply(employed[,14:31], flevels)
employed[,39:86] <- lapply(employed[,39:86], flevels2)
employed[,91:120] <- lapply(employed[,91:120], flevels2)

learner[,12:28] <- lapply(learner[,12:28], flevels)
learner[,31:40] <- lapply(learner[,31:40], flevels3)

employed.LP <- employed[,14:31]
employed.WT <- employed[,39:86]
employed.WM <- employed[,91:120]

learner.LP <- learner[,12:28]
learner.JS <- learner[,31:40]
```

## Exploratory Data Analysis (EDA)

First let's take a look at the demographics of the survey respondents and what type of jobs they hold. 

### Employed Data Scientists

About 30% of or survey respondents would call themselves "Data Scientists" with about another 20 percent calling themselves either "Scientist/Researcher" or "Software Developer/Software Engineer".  So about 50% of our survey respondents fall in these three categories with the other 50% in other roles.  

```{r echo=FALSE}
# Take a peek at the demographics of those who are employed...
kable(employed %>% 
  group_by(CurrentJobTitleSelect) %>%
  summarise(total = n()) %>%
  mutate(percent = round(total / sum(total), 4)*100) %>%
  arrange(desc(total)))

# Need to Tidy this data so that each response is in a separate row rather than all in one
# employed %>% 
#  group_by(CurrentEmployerType) %>%
#  summarise(total = n()) %>%
#  arrange(desc(total))
```

### 'Learners'

The Kaggle survey asked respondents if they were learning data science and their student status.  73% of the respondents who said they were learning data science are enrolled in an academic program.  

```{r echo=FALSE}
# Take a peek at the demographics of those who are learners...
kable(learner %>% 
  group_by(StudentStatus) %>%
  summarise(total = n()) %>%
  mutate(percent = round(total / sum(total), 4)*100) %>%
  arrange(desc(total)))
```

55% of all respondents who said they are learning data science said they are "focused on learning mostly data science skills" with the other 45% saying that "data science is a small part of what I’m focused on learning".

The ratio of respondents who said they are "focused on learning mostly data science skills" remains the same at about 55% regardless of whether or not they are enrolled in an academic program.

```{r echo=FALSE}
# Take a peek at the demographics of those who are learners...
kable(learner %>% 
  group_by(StudentStatus, LearningDataScience) %>%
  summarise(total = n()) %>%
  mutate(percent = round(total / sum(total), 4)*100) %>%
  arrange(desc(total)))
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

learner.LPL <- likert(data.frame(learner.LP))
learner.JSL <- likert(data.frame(learner.JS))

employed.LPL <- likert(data.frame(employed.LP))
employed.WTL <- likert(data.frame(employed.WT))
employed.WML <- likert(data.frame(employed.WM))
```

### Learning Platform Usefulness - 'Learners'

'Learners' think that the top 3 best ways to learn data science are through Courses, Projects and College with Arxiv and YouTube coming in 4th and 5th respectively.  

```{r echo=FALSE}
plot(learner.LPL)
kable(summary(learner.LPL))
```

### Learning Platform Usefulness - Employed Data Scientists

Employed Data Scientists agree with unemployed 'Learners' that Projects and Courses belong in the top 3, but put College in 5th place (vs. 3rd).  They also include Tutoring and SO (Stack Overflow Q&A) in their top 5 with SO coming in 2nd place.  YouTube (learner's 5th choice) comes in 14th place for employed Data Scientists and Arxiv (learner's 4th choice) is 8th among employed Data Scientists. 

Another interesting difference is that the importance of Friends to learning data science is much higher among employed Data Scientists with about 46.5% saying that Friends are "Very useful" and 97.5% saying that Friends are either "Somewhat useful" or "Very useful" vs. 'Learners' who put Friends at absolute bottom of their list with only 17.6% saying that they are are "Very useful" and 82.4% saying that Friends are either "Somewhat useful" or "Very useful".  

This may indicate a need to create a more robust community for Data Science 'Learners', who may feel somewhat isolated in their studies vs. employed Data Scientists who presumably have more established work and social networks that involve Data Science.  

```{r echo=FALSE}
plot(employed.LPL)
kable(summary(employed.LPL))
```

### Job Skills Importance to 'Learners'

'Learners' put Python at the top of their list of Job Skills with 63.6% of respondents saying that it is "Necessary" and 99% saying it is either "Necessary" or "Nice to have".  Only 1% said it was "Unnecessary".  R is surprisingly further down the list with only a little more than half as many respondents saying that R is "Necessary" compared to Python at 34.7% but many more agreeing that it is at least "Nice to have" for a total of 95% in favor of learning R which is just slightly less than those in favor of Python.

Surprisingly "Data Visualization" comes in only slightly above R with 39% saying that it is "Necessary" but actually slightly lower in terms of overall importance with 8% saying it is "Unnecessary".

```{r echo=FALSE}
plot(learner.JSL)
kable(summary(learner.JSL))
```

### Work Tools Frequency

Not surprisingly I guess, Python is also high on the list of tools that working Data Scientists use with 75.4% of users saying that they use it either "Often" or "Most of the time" and only Statistica, SQL and Unix edging it out for the top 3 slots.  What is surprising is that two of the the top three tools used in the field aren't even on the list of Job Skills 'Learners' were asked to evaluate.

R comes in slightly lower than Python with 63.6% of users saying that they use it either "Often" or "Most of the time" but the difference between R and Python is less in the field than what 'Learners' seem to think is most important.


```{r echo=FALSE, fig.height = 10, fig.width = 10, fig.align = "center" , message= FALSE}

plot(employed.WTL)
kable(summary(employed.WTL))
```

### Work Methods Frequency

The big surprise here is that Data Visualization is at the top of the list.  With nobody saying that they use it "Rarely" and only 8.5% saying that they only use it "Sometimes".  91.5% say they use it "Often" or "Most of the time".  It is by far the most frequently used method or tool for working Data Science Professionals with Statstica as the next runner up at only 80% by comparison.  Remember that only 38.8% of 'Learners' said that they thought Visualizations were a "Necessary" job skill to learn!  

```{r echo=FALSE}
plot(employed.WML)
kable(summary(employed.WML))
```

<br>

# R vs. Python

The most frequently used of the programming languages are R and Python. But do those that use R recommend R or Python?  And do those that use Python recommend R or Python?  In other words, do those survey takers feel that others should first and foremost study the languages they themselves have taken up, or perhaps with their insight, know to suggest the language of the two they themselves did not learn?

Thus the following questions were explored:
 
1. What is the distribution of following programming languages Kaggle survey takers used in the past year:  

   + R Only
   + Python only
   + Both Python and R
   + Neither Python nor R
    
2. What is the distribution of programming language recommendations by following programming languages Kaggle survey takers used in the past year:   

   + Using R Only
   + Using Python only
   + Using Both Python and R
   + Using Neither Python nor R

## Variables and their definition 

There are 2 variables used in this section of the analysis :

1. LanguageRecommendationSelect=(What programming language would you recommend a new data scientist learn first? (Select one option) - Selected Choice)  

2. WorkToolsSelect= For work, which data science/analytics tools, technologies, and languages have you used in the past year? (Select all that apply) - Selected Choice  

## Manipulating data

The major task in this part of the analysis was to create a tidy data structure  This can be accomplished using Select function calls and the required variables for the analysis. Because the respondents were provided the option of choosing anything that applied to them, the data for the languages were captured as strings as opposed to having one language as a column for each respondent.

## Exploratory Data Analysis (EDA)

```{r ,fig.height = 8, fig.width = 8, fig.align = "center" , message= FALSE}
dim(MC)
tb1<-MC %>%
  select (id, WorkToolsSelect) %>%
  filter (id %in% c(1:6))
   datatable(tb1)
   

#removing NAs and empty values in  column=WorkToolsSelect
df <- MC[!(MC$WorkToolsSelect == "" | is.na(MC$WorkToolsSelect)), ]
dim(df)
tb2<-df %>%
  select (id, WorkToolsSelect) %>%
  filter (id %in% c(1:6))
   datatable(tb2)

#creating a new variable called work_tools where the original column values are split 
#please note that this code will generate long data   
df1<-df %>%
  mutate(work_tools = strsplit(as.character(WorkToolsSelect), ",")) %>%
  unnest(work_tools)

  #check 
tb3<-df1 %>%
  select (id, WorkToolsSelect,work_tools) %>%
  filter (id %in% c(1:3))
   datatable(tb3)

 df2<-df1  %>%
 group_by(id, work_tools) %>%
  summarize (total_count = n())   %>%
    spread( work_tools, total_count, fill=0) 


df3<-df2 %>%
 mutate(lang_use = case_when (
               (R==1 & Python==0) ~ "Using R Only",
               (R==0 & Python==1) ~ "Using Python only",
               (R==1 & Python==1) ~ "Using Both Python and R",
               (R==0 & Python==0) ~ "Using Neither Python nor R"))%>%
  select (id, R, Python, lang_use)

tb4<-df3 %>%
filter (id %in% c(1:10))
datatable(tb4)

#computing percentages
df4<-df3 %>%
group_by(lang_use) %>%
summarize (total_count = n()) %>%
mutate(percent = ((total_count / sum(total_count)) * 100), percent=round(percent, digit=2))

 #checking
datatable(df4, colnames=c("Programming Language Survey takers use", "Count", "Percent"),class = 'cell-border stripe',caption = 'Table 1: Descriptive Statistics',options = list(pageLength = 4, dom = 'tip'))


p<-ggplot (df4, aes(x=lang_use,y=percent,fill=lang_use )) +
geom_bar(stat="identity", width =.5) +
labs (x="Language ", y="The distribution of R and Python among their users (%) " ,
      title="Bar Graph of R and Python users") +
theme(axis.text.x = element_text(angle = 90), legend.position = 'none') +
scale_y_continuous (breaks=seq(0,100,10), limits = c(0,100))
p
# ggplotly(p)



```

Let's examine the above graph of LanguageRecommendationSelect

```{r ,fig.height = 10, fig.width = 10, fig.align = "center" , message= FALSE}

 #check 
tb5<-df1 %>%
  select (id, WorkToolsSelect,work_tools, LanguageRecommendationSelect) %>%
  filter (id %in% c(1:3))
   datatable(tb5)

 df5<-df1  %>%
 group_by(id, work_tools,LanguageRecommendationSelect) %>%
  summarize (total_count = n())   %>%
    spread( work_tools, total_count, fill=0) %>%
 mutate(lang_use = case_when (
               (R==1 & Python==0) ~ "Using R Only",
               (R==0 & Python==1) ~ "Using Python only",
               (R==1 & Python==1) ~ "Using Both Python and R",
               (R==0 & Python==0) ~ "Using Neither Python nor R"),
        lang_rec = case_when (
               (LanguageRecommendationSelect=="R") ~ "Recommending R ",
               (LanguageRecommendationSelect=="Python" ) ~ "Recommending Python ",
               (LanguageRecommendationSelect!="R" |LanguageRecommendationSelect!="Python") ~ "Recommending Neither Python nor R",
               (LanguageRecommendationSelect=="NA"|LanguageRecommendationSelect==" " ) ~ "Recommending Nothing"))%>%
select (id, R, Python, lang_use,lang_rec )

 dim(df5)
 
tb6<-df5 %>%
filter (id %in% c(1:10))
datatable(tb6)

 #computing percentages
df6<-df5 %>%
group_by(lang_use,lang_rec) %>%
summarize (total_count = n()) %>%
mutate(percent = ((total_count / sum(total_count)) * 100), percent=round(percent, digit=2))

#checking
datatable(df6, colnames=c("Programming Language Survey takers use", "Count", "Percent"),class = 'cell-border stripe',caption = 'Table 1: Descriptive Statistics',options = list(pageLength = 4, dom = 'tip'))


p1<-ggplot (df6, aes(x=lang_use,y=percent,fill=lang_use )) +
geom_bar(stat="identity", width =.5) +
labs (x="Language ", y="The distribution of R and Python among their users (%) " ,
title="Bar Graph of R and Python users and their recommended language") +
theme(axis.text.x = element_text(angle = 90)) +
scale_y_continuous (breaks=seq(0,100,10), limits = c(0,100))+
  facet_wrap(~lang_rec)+
  theme(legend.position = 'none')
p1
# ggplotly(p1)

```

## Results of Exploring R vs. Python:


We found that *a little below the half of the survey takers* (N=3540, 44.5%) reported to use both R and Python. The take home message for aspiring data scientists is that a substantial majority of the Kaggle survey takers are using both languages--both languages are used widely. Among the remaining half of the respondents, a small portion of them (N=714, 8.98%) are using neither Python nor R. The rest of the survey takers are using either R or Python. In particular, 2533 (31.84%) indicated using only Python while only 1168 (14.68%) of them reported using R Only.

The story of this contentious debate on R vs Python gets more interesting when comparing their used languages with their recommended languages. Specifically, it is plausible to assume that Python users will recommend Python while R users will recommend R. We explore this hypothesis by comparing the difference of R users recommending R and Python and the difference of Python users recommending R and Python.

Our results revealed that 72.17 % of the Python users recommended Python while 53.77% of R users recommended R. This result is not surprising--there are more Python only users than R only users in this sample, it makes sense to have differences in their recommendations since a different proportion of each know only the one language. However, what is surprising is the degree of difference in their recommendation for the other language: 15.92 % of the R users recommend Python whereas only 1.42 % of the Python users recommend R. 


However, these results should be interpreted carefully because there are survey takers who did not make any recommendation. For instance 18.87% of the sample who are Python users did not respond to this question. Similarly, 17.55% of R users did not leave any opinion on their recommended languages. This is a sizable portion of the sample and if these users were to make recommendations, it's possible that more Python users would be recommending R.


Since half the sample included respondeds who are both R and Python users, their recommendation is particularly valuable since they have experience with both languages. Of this subset, 51.72% of them recommend Python while 25.65% of them recommend R. A quarter of the users that use both reccomend R over Python.

<br>

# Salary Comparison for Python vs. R

Finally, true to the word "value," considerations have to be made regarding pay. The compensation received by survey takers for their work in either R or Python needs quantification to discover which language earns a data scientist more overall and in general.

## Contributing Variables

What the question is primarily concerned with is three-fold:

* __WorkToolsSelect__: This was a "select all that apply" variable with a list of various data science tools, technologies, and languages. Survey takers identified which tools were utilized in their work and the results were stored in this comma separated variable.
* __CompensationAmount__: This was a numerical value to be entered by the survey taker indicating their annual pay.
* __CompensationCurrency__: This was a simple character string that stated what currency the survey taker was receiving their annual salary in.

There was also the variable "id" that was created for the purpose of this report, acting as a way to identify each individual survey taker, and the variable "work_tools" which was a derivative of WorkToolsSelect, breaking the lists down into their individual components.

## Preparing the data

```{r}
RQ6 <- MC %>%
  mutate(work_tools = strsplit(as.character(WorkToolsSelect), ",")) %>% 
  unnest(work_tools)

RQ6 <- RQ6 %>%
  filter(!is.na(WorkToolsSelect)) %>%  # Filters out all columns with NA in the WorkToolsSelect column
  filter(CompensationCurrency == "USD") %>% # Makes sure to only use rows whose currency is in USD
  filter(work_tools == "Python" | work_tools == "R") %>% # The work tools are R or Python, period.
  select(id, work_tools, CompensationAmount) # Only have three rows to work with
RQ6_ids <- select(filter(as.data.frame(table(RQ6$id)), Freq == 1), Var1) # Only want people who use R or Python EXCLUSIVELY, not R and/or Python
RQ6_ids <- droplevels(RQ6_ids)$Var1 # Removed the levels so we can actually get the IDs
RQ6 <- filter(RQ6, id %in% RQ6_ids) # Only keep those rows whose id are inside of list of ids with R or Python exclusively used at work
RQ6 <- select(RQ6, -id) # No use for the ID anymore, it's done its job
RQ6$CompensationAmount <- gsub(",", "", RQ6$CompensationAmount) # Removed the commas from the compensation amount to prep for numeric transformation
RQ6$CompensationAmount <- as.numeric(RQ6$CompensationAmount) # made the column into a numeric for easier mathematical comparison and sorting
RQ6 <- filter(RQ6, CompensationAmount < 9999999) # ... let's just be a little realistic, nobody is earning more than fifteen million a year at this point in time or prior to it, and this one-dollar-off-from-a-million entry is an anomaly in the data set
RQ6.summary <- rbind(summary(select(filter(RQ6, work_tools=="Python"), CompensationAmount)[[1]]), summary(select(filter(RQ6, work_tools=="R"), CompensationAmount)[[1]])) # Summary of the data
RQ6.summary <- as.data.frame(RQ6.summary)
colnames(RQ6.summary) <- c("Minimum", "1st Quartile", "Median", "Mean", "3rd Quartile", "Maximum") # Renamed the columns
RQ6.summary["Standard Deviation"] <- c( sd(filter(RQ6, work_tools == "Python")$CompensationAmount), sd(filter(RQ6, work_tools == "R")$CompensationAmount) )
RQ6.summary <- as.data.frame(sapply(RQ6.summary, function (x) paste("$", formatC(x, digits=2, format="f", big.mark=","), sep="") )) # Made all of the items in the data frame into dollar format
rownames(RQ6.summary) <- c("Python", "R") # Applied the rownames
rm(RQ6_ids) # remove the now-unused variable to save memory
```

In order to study the data to answer this question, it had to first be transformed. All users who did not provide an answer for the question on tools they use at work had their responses discarded. Similarly, all users whose compensation was not in US Dollars had their information disregarded in order to hone in on a single socio-economic focus, the US market. A separate table was created pairing survey takers with each of their languages or methods used for their job via the id variable - a number assigned to each survey taker - and work_tools variable, which stored each item in the list provided by WorkToolsSelect in its own row, matched to the id of the survey taker who provided it. Using this separate table, survey takers who used both Python and R in their jobs were removed, and any who failed to use R or Python in their job were removed as well, leaving a list of individuals who exclusively used Python or R in their career. Lastly, the amounts compensated were reformatted so as to be in a numeric format and any rows with an unlikely compensation amount - north of ten million annually - were removed to prevent data skewing by such a severe outlier.

## Exploration and Review of Compensations

```{r}
RQ6_boxplot <- ggplot(RQ6) +
  geom_boxplot( aes(x = factor(work_tools), 
                    y = CompensationAmount,
                    fill = factor(work_tools)
                     )
                  ) +
  scale_y_continuous(breaks=seq(0,2000000,25000)) +
  labs( x = "Programming Language",
        y = "Annual Compensation in USD",
        fill = "Programming Language")
RQ6_boxplot_ylim <- boxplot.stats(RQ6$CompensationAmount)$stats[c(1, 5)]
RQ6_boxplot <- RQ6_boxplot + coord_cartesian(ylim = RQ6_boxplot_ylim*1.05)
RQ6_boxplot
```

As we can see from the boxplots there is relatively normal distribution present in the compensation for those who solely used Python in their work. Conversely, there is a noticeable right skew in the compensation for those who solely used R in their work.

```{r}
knitr::kable(RQ6.summary)
```

The average survey taker who used Python in their job made approximately \$`r formatC(colMeans(select(filter(RQ6, work_tools=="Python"),CompensationAmount))-colMeans(select(filter(RQ6, work_tools=="R"),CompensationAmount)), digits=2, format="f", big.mark=",")` more than the average survey taker who used R in their job. While R users overall had a higher base pay - to the tune of $`r formatC(quantile(select(filter(RQ6, work_tools=="R"),CompensationAmount)[[1]])["25%"]-quantile(select(filter(RQ6, work_tools=="Python"),CompensationAmount)[[1]])["25%"], digits=2, format="f", big.mark=",")` more than their Python counterparts - their ability to achieve growth in salary was noticeably stymied in comparison. Outliers aside, if the data collected is to be considered representative of the data science population, there is indication that a prospective Data Scientist should learn R first for a higher initial salary, and then learn Python to increase their chance of obtaining a job with more growth potential.

<br>

# Conclusion

**On the contentious debate on which Machine Learning/Data Science methods Data Scientists are most excited about learning in the next year as the most valued Data Science Skills**

+ *Deep Learning* is the top most Machine Learning/Data Science method in all categories of formal education followed by *Neural Nets* except High school graduates, all others wants to learn
+ *Time Series Analysis* as the third Machine Learning/Data Science method. High school graduates want to learn Genetic & Evolutionary Algorithms as their third choice. 
+ Among doctoral survey takers, *Bayesian Methods* is the third preference.

**On Data Science Methods Used on the Job**

+ *Data Visualization* is a remarkably popular data science method.  It is the most endorsed by *nearly all education attainment levels*.
+ *Cross validation, random forests, logistic regression, and decision trees* are also heavily endorsed.
+ These are not just short but required or essential tasks--not only do so many of those writing code use data visualization, but they also use it quite frequently
+ The data suggest that data science methods do *not* differ much between formal educational attainment groups.


**'Learners' vs. Employed Data Scientists**

+ Both Learners and employed Data Scientists agree that Courses, Projects and College are in the top three ways to learn Data Science
+ 'Learners' place much less importance on Friends for learning than employed Data Scientists do
+ 'Learners' place a higher importance on Python vs. R as compared with employed Data Scientists
+ Data Visualization is the top used skill for working Data Scientists even though learners put relatively little importance on it as a Job Skill

**On Data Science Activities**

+ *Gathering Data* is the main activity where data scientists spend most of their time followed by model building. 
+ *Personal projects and Online Courses* appear to be very useful learning platforms.

**On the contentious debate on R vs Python as the most valued Data Science Skills**  

+ Half of the sample uses both R and Python    
+ R only to Python only users are in 1:2 ratio    
+ More R users recommended Python than the Python users recommended R   
+ Both users recommendations in Python is more than their recommendation in R   
+ R users are more likely to have a higher base salary, but Python users have the greater potential for wage growth



